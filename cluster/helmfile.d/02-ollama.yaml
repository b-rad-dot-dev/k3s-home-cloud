repositories:
  - name: ollama-helm
    url: https://otwld.github.io/ollama-helm/

releases:
  - name: ollama
    namespace: ollama
    chart: ollama-helm/ollama
    version: 1.11.0
#    version: 1.30.0
    values:
      - image:
          tag: 0.12.2
      - runtimeClassName: nvidia
      - nodeSelector:
          nvidia.com/gpu.memory: "4096" # TODO: Switch with 8192 / comfyui?
      - persistentVolume:
          enabled: true
          storageClass: nfs-csi
      - service:
          type: LoadBalancer
      - ollama:
          gpu:
            enabled: true
            type: nvidia
            number: 1
          models:
            pull:
              - phi4-mini
              - deepseek-r1:1.5b
              - qwen3:4b
              - llama3.2:3b
            run:
              - llama3.2:3b