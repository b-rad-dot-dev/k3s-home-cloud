apiVersion: v1
kind: ConfigMap
metadata:
  name: librechat-config
data:
  librechat.yaml: |
    version: 1.2.8
    interface:
      mcpServers:
        placeholder: "MCP Servers"
    mcpServers:
      mcp-gateway:
        type: streamable-http
        url: http://mcp-gateway.mcp:8080/mcp
        serverInstructions: true
    endpoints:
      custom:
        - name: "Ollama"
          apiKey: "ollama"
          baseURL: "http://ollama.ollama:11434/v1/"
          models:
            default: [
              "phi4-mini",
              "deepseek-r1:1.5b",
              "llama3.2:3b",
              "qwen2.5:3b-instruct-q8_0"
            ]
            fetch: true
          titleConvo: true
          titleModel: "current_model"
          summarize: false
          summaryModel: "current_model"
          forcePrompt: false
          modelDisplayLabel: "Ollama"
        - name: "LM Studio"
          apiKey: "not-needed"
          baseURL: "http://lm-studio.default/v1"
          models:
            default: [
              "qwen/qwen3-30b-a3b-2507"
            ]
            fetch: true
          titleConvo: true
          titleModel: "current_model"
          summarize: false
          summaryModel: "current_model"
          forcePrompt: false
          modelDisplayLabel: "LM Studio"
